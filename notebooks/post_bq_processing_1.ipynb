{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.multiprocessing import get\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up movers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movers = dd.read_csv(\n",
    "    '/home/ubuntu/projects/infutor_wip/data/bay_area_movers*.csv',\n",
    "    dtype={'county_seq_' + str(x): str for x in range(1, 11)},\n",
    "    assume_missing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movers['not_valid'] = (\n",
    "    (movers.addrid_seq_1.notnull() & movers.effdate_seq_1.isna()) |\n",
    "    (movers.addrid_seq_2.notnull() & movers.effdate_seq_2.isna()) |\n",
    "    (movers.addrid_seq_3.notnull() & movers.effdate_seq_3.isna()) |\n",
    "    (movers.addrid_seq_4.notnull() & movers.effdate_seq_4.isna()) |\n",
    "    (movers.addrid_seq_5.notnull() & movers.effdate_seq_5.isna()) |\n",
    "    (movers.addrid_seq_6.notnull() & movers.effdate_seq_6.isna()) |\n",
    "    (movers.addrid_seq_7.notnull() & movers.effdate_seq_7.isna()) |\n",
    "    (movers.addrid_seq_8.notnull() & movers.effdate_seq_8.isna()) |\n",
    "    (movers.addrid_seq_9.notnull() & movers.effdate_seq_9.isna()) |\n",
    "    (movers.addrid_seq_10.notnull() & movers.effdate_seq_10.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 45.3s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    validated_movers = movers.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_movers = validated_movers[validated_movers['not_valid'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_movers.to_parquet('../data/cleaned_movers.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process movers wide to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_movers = dd.read_parquet('../data/cleaned_movers.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_movers = cleaned_movers.repartition(npartitions=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    \n",
    "    sttm = time.time()\n",
    "    out_cols = ['pid', 'from_addrid', 'to_addrid', 'from_effdate', 'to_effdate', 'from_county', 'to_county', 'seq']\n",
    "    long_moves = pd.DataFrame(columns=out_cols, dtype=str)\n",
    "    \n",
    "    for x in range(1,10):\n",
    "\n",
    "        from_county_col = 'county_seq_' + str(x)\n",
    "        to_county_col = 'county_seq_' + str(x + 1)\n",
    "        from_addrid_col = 'addrid_seq_' + str(x)\n",
    "        to_addrid_col = 'addrid_seq_' + str(x + 1)\n",
    "        from_effdate_col = 'effdate_seq_' + str(x)\n",
    "        to_effdate_col = 'effdate_seq_' + str(x + 1)\n",
    "    \n",
    "        tmp = df[[\n",
    "            'pid_a', from_addrid_col, to_addrid_col, from_effdate_col, \n",
    "            to_effdate_col, from_county_col, to_county_col]].copy(deep=True)\n",
    "        tmp.loc[:, 'seq'] = x\n",
    "        long_moves = pd.concat((long_moves, tmp.rename(columns=dict(zip(tmp.columns, out_cols)))))\n",
    "\n",
    "    return long_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = ['pid', 'from_addrid', 'to_addrid', 'from_effdate', 'to_effdate', 'from_county', 'to_county', 'seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_movers = cleaned_movers.map_partitions(process_df, meta=pd.DataFrame(columns=out_cols, dtype=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[###################                     ] | 48% Completed |  7min 21.8s"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    all_moves = long_movers.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_moves) == len(cleaned_movers) * 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows without full to/from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_moves = dd.from_pandas(all_moves, npartitions=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_not_null = all_moves[all_moves['from_effdate'].notnull() & all_moves['to_effdate'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 36.0s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    moves_not_null = moves_not_null.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16713668"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moves_not_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows where move is between the same address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_not_dupe = moves_not_null[moves_not_null['from_addrid'] != moves_not_null['to_addrid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14768635"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moves_not_dupe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves_not_dupe.to_parquet('../data/moves_long.parquet', engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:infutor]",
   "language": "python",
   "name": "conda-env-infutor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
